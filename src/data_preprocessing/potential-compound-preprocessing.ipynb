{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notification__: The raw data from PubChem database have many errors and duplicates, therefore, this file perform the cleaning it.\n",
    "- Use the my-rdkit-env environment\n",
    "- The data that we used after preprocessing is availible in this link: https://drive.google.com/file/d/1YIhBD51oWA0s3p-egIHepNb3iZZbXqb1/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "import os\n",
    "import psycopg2\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import logging\n",
    "\n",
    "#MACCS\n",
    "from tqdm import tqdm\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Descriptors import ExactMolWt\n",
    "from rdkit import RDLogger  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/tuele/.vscode/qsar_ml_find_hdac2_inhibitor/output/logs/100mil-hdac2-preprocessing.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlogging\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbasicConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../../output/logs/100mil-hdac2-preprocessing.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogging\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINFO\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/logging/__init__.py:2050\u001b[0m, in \u001b[0;36mbasicConfig\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m   2048\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2049\u001b[0m         encoding \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mtext_encoding(encoding)\n\u001b[0;32m-> 2050\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[43mFileHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2051\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2052\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2053\u001b[0m     stream \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/logging/__init__.py:1181\u001b[0m, in \u001b[0;36mFileHandler.__init__\u001b[0;34m(self, filename, mode, encoding, delay, errors)\u001b[0m\n\u001b[1;32m   1179\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     StreamHandler\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/logging/__init__.py:1213\u001b[0m, in \u001b[0;36mFileHandler._open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;124;03mOpen the current base file with the (original) mode and encoding.\u001b[39;00m\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;124;03mReturn the resulting stream.\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m open_func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_builtin_open\n\u001b[0;32m-> 1213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopen_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbaseFilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/tuele/.vscode/qsar_ml_find_hdac2_inhibitor/output/logs/100mil-hdac2-preprocessing.txt'"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(filename='../../output/logs/100mil-hdac2-preprocessing.txt', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PubchemDAO:\n",
    "    \"\"\"\n",
    "    Data access object of the PubChem raw data, the table include two columns: pubchem_compounds_cid, and pubchem_openeye_iso_smiles\n",
    "    \"\"\"\n",
    "    \n",
    "    SELECT_DATA_BETWEEN_CID = \"\"\"SELECT * FROM \n",
    "        compound_screen_10mil WHERE pubchem_compound_cid >= %s and pubchem_compound_cid <= %s;\"\"\"\n",
    "    MAX_CID_QUERY = \"SELECT MAX(pubchem_compound_cid) FROM compound_screen_10mil\"\n",
    "    MIN_CID_QUERY = \"SELECT MIN(pubchem_compound_cid) FROM compound_screen_10mil\"\n",
    "    \n",
    "    max_cid = None\n",
    "    min_cid = None\n",
    "    connection = None\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Create connection\n",
    "        load_dotenv(\"../env/.env\")\n",
    "        self.connection = psycopg2.connect(os.environ['DATABASE_URL'])\n",
    "        # Get the max_cid and min_cid\n",
    "        self.get_min_max_cid()\n",
    "        logging.info(f\"Min CID - Max CID: {self.min_cid} - {self.max_cid}\")\n",
    "    \n",
    "    def get_min_max_cid(self):\n",
    "        with self.connection:\n",
    "            with self.connection.cursor() as cursor:\n",
    "                cursor.execute(self.MIN_CID_QUERY)\n",
    "                self.min_cid = cursor.fetchall()[0][0]\n",
    "                cursor.execute(self.MAX_CID_QUERY)\n",
    "                self.max_cid = cursor.fetchall()[0][0]\n",
    "        \n",
    "    def get_data_between_cid(self, first_cid, second_cid):\n",
    "        if(first_cid < self.min_cid or second_cid > self.max_cid):\n",
    "            logging.info(\"Invalid cid!\")\n",
    "            return\n",
    "        with self.connection:\n",
    "            with self.connection.cursor() as cursor:\n",
    "                cursor.execute(self.SELECT_DATA_BETWEEN_CID, (first_cid, second_cid))\n",
    "                data_list = cursor.fetchall()\n",
    "                column_names = [desc[0] for desc in cursor.description]\n",
    "                return pd.DataFrame(data_list, columns=column_names)\n",
    "\n",
    "class PubchemScreeningDAO:  \n",
    "    \"\"\"\n",
    "    Data access object of the data after preprocessed the PubChem database, \n",
    "        the table include 4 columns: id, cid, smiles, molecular_weight\n",
    "    \"\"\"  \n",
    "    CREATE_PREPROCESSING_TABLE = \"\"\"CREATE TABLE IF NOT EXISTS pubchem_compound_preprocessed (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        cid INTEGER UNIQUE NOT NULL, \n",
    "        smiles TEXT UNIQUE NOT NULL,\n",
    "        molecular_weight decimal NOT NULL\n",
    "    );\n",
    "    CREATE INDEX IF NOT EXISTS idx_cid ON pubchem_compound_preprocessed (cid);\n",
    "    \"\"\"\n",
    "    INSERT_COMPOUND = \"INSERT INTO pubchem_compound_preprocessed (cid, smiles, molecular_weight) VALUES (%s, %s, %s);\"\n",
    "    SELECT_FIRST_DATA = \"SELECT * FROM pubchem_compound_preprocessed LIMIT %s;\"\n",
    "    SELECT_DATA_BY_CID = \"\"\"SELECT * FROM pubchem_compound_preprocessed WHERE cid = %s\"\"\"\n",
    "    SELECT_NUMBERS_OF_ROWS = \"\"\"SELECT COUNT(*) as row_count FROM pubchem_compound_preprocessed;\"\"\"\n",
    "    MAX_CID_QUERY = \"SELECT MAX(cid) FROM pubchem_compound_preprocessed\"\n",
    "    MIN_CID_QUERY = \"SELECT MIN(cid) FROM pubchem_compound_preprocessed\"\n",
    "    \n",
    "    connection = None\n",
    "    \n",
    "    def __init__(self):\n",
    "        load_dotenv(\"../env/.env\")\n",
    "        self.connection = psycopg2.connect(os.environ['DATABASE_URL'])\n",
    "\n",
    "    def create_tables(self):\n",
    "        with self.connection:\n",
    "            with self.connection.cursor() as cursor:\n",
    "                cursor.execute(self.CREATE_PREPROCESSING_TABLE)\n",
    "    \n",
    "    def read_first_rows(self, number_of_data):\n",
    "        with self.connection:\n",
    "            with self.connection.cursor() as cursor:\n",
    "                cursor.execute(self.SELECT_FIRST_1000_ALL_DATA, number_of_data)\n",
    "                column_names = [desc[0] for desc in cursor.description]\n",
    "                data_list = cursor.fetchall()\n",
    "                return pd.DataFrame(data_list, columns=column_names)\n",
    "    \n",
    "    def insert(self, cid, smiles, molecular_weight):\n",
    "        with self.connection:\n",
    "            with self.connection.cursor() as cursor:\n",
    "                try:\n",
    "                    cursor.execute(self.INSERT_COMPOUND, (cid, smiles, molecular_weight))\n",
    "                    return True\n",
    "                except psycopg2.IntegrityError as error:\n",
    "                    if 'duplicate key value violates unique constraint' in str(error):\n",
    "                        logging.error(f\"Skipping data with cid={cid} due to unique constraint violation.\")\n",
    "                    else:\n",
    "                        logging.error(str(error))\n",
    "                        raise  # Re-raise the exception if it's not related to unique constraint violation\n",
    "                except Exception as e:\n",
    "                    logging.error(\"An exception occurred: \" + str(e))\n",
    "        return False  # Return False if no successful insertion or if an exception occurs\n",
    "    \n",
    "    def get_number_of_rows(self):\n",
    "        with self.connection:\n",
    "            with self.connection.cursor() as cursor:\n",
    "                cursor.execute(self.SELECT_NUMBERS_OF_ROWS)\n",
    "                nor = cursor.fetchall()\n",
    "                return nor\n",
    "            \n",
    "    def get_min_max_cid(self):\n",
    "        with self.connection:\n",
    "            with self.connection.cursor() as cursor:\n",
    "                cursor.execute(self.MIN_CID_QUERY)\n",
    "                min_cid = cursor.fetchall()[0][0]\n",
    "                cursor.execute(self.MAX_CID_QUERY)\n",
    "                max_cid = cursor.fetchall()[0][0]\n",
    "                return min_cid, max_cid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the train - test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_path = \"../../data_for_modeling/train_test_data/HDAC2_train_test_data_final.xlsx\"\n",
    "train_dataset = pd.read_excel(train_test_path, sheet_name='train_dataset')\n",
    "test_dataset = pd.read_excel(train_test_path, sheet_name='test_dataset')\n",
    "validation_dataset = pd.read_excel(train_test_path, sheet_name='validation_dataset')\n",
    "\n",
    "train_test_dataset = pd.concat([train_dataset, test_dataset, validation_dataset], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016 281 504 2801\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset), len(test_dataset), len(validation_dataset), len(train_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CID</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>AVG_IC50_nM</th>\n",
       "      <th>FINAL_LABEL</th>\n",
       "      <th>ZBG Classified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44138033</td>\n",
       "      <td>COC(=O)c1ccc(CO/N=C/c2ccc(/C=C/C(=O)NO)cc2)cc1</td>\n",
       "      <td>15800.0</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>164616411</td>\n",
       "      <td>CC[C@H](NC(=O)C1CN(C)C1)c1ncc(-c2cc3ccccc3nc2O...</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>135357843</td>\n",
       "      <td>O=C(NO)c1ccc(Cn2nnnc2-c2cccs2)cc1</td>\n",
       "      <td>3698.0</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>142506189</td>\n",
       "      <td>CC[C@H](Nc1ncnc2[nH]cnc12)c1nc2cccc(NCc3ccc(C(...</td>\n",
       "      <td>7173.0</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155537112</td>\n",
       "      <td>CN(C)c1ccc(C(=O)N(CC(=O)NCc2ccccc2)Cc2ccc(C(=O...</td>\n",
       "      <td>283.0</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CID                                             SMILES  AVG_IC50_nM  \\\n",
       "0   44138033     COC(=O)c1ccc(CO/N=C/c2ccc(/C=C/C(=O)NO)cc2)cc1      15800.0   \n",
       "1  164616411  CC[C@H](NC(=O)C1CN(C)C1)c1ncc(-c2cc3ccccc3nc2O...      50000.0   \n",
       "2  135357843                  O=C(NO)c1ccc(Cn2nnnc2-c2cccs2)cc1       3698.0   \n",
       "3  142506189  CC[C@H](Nc1ncnc2[nH]cnc12)c1nc2cccc(NCc3ccc(C(...       7173.0   \n",
       "4  155537112  CN(C)c1ccc(C(=O)N(CC(=O)NCc2ccccc2)Cc2ccc(C(=O...        283.0   \n",
       "\n",
       "  FINAL_LABEL  ZBG Classified  \n",
       "0    Inactive               1  \n",
       "1    Inactive              15  \n",
       "2    Inactive               1  \n",
       "3    Inactive               1  \n",
       "4    Inactive               4  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking and insert data into the preprocessing table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_error_fpts(check_dataset, smiles_column):\n",
    "    \"\"\"\n",
    "    Checks for errors in MACCS fingerprint calculation.\n",
    "\n",
    "    Args:\n",
    "        check_dataset (pd.DataFrame): The dataset to be checked.\n",
    "        smiles_column (str): The name of the SMILES column.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The rows with errors in MACCS fingerprint calculation.\n",
    "    \"\"\"\n",
    "    result_df = pd.DataFrame(columns=check_dataset.columns)\n",
    "    for index, row in check_dataset.iterrows():\n",
    "        current_smiles = str(row[smiles_column]).strip()\n",
    "        if current_smiles is not None and len(current_smiles) > 0:\n",
    "            try:\n",
    "                RDLogger.DisableLog('rdApp.info')\n",
    "                mol = Chem.MolFromSmiles(current_smiles)\n",
    "                if mol is not None:\n",
    "                    result_df = pd.concat([result_df, row.to_frame().T], axis=0)  # Concatenate the current row                \n",
    "                else:\n",
    "                    logging.info(\"Could not interpret \" + current_smiles + \" to mol object!\")\n",
    "            except Exception as e:\n",
    "                logging.error(\"An exception occurred at row \" + str(index) + \": \" + str(e))\n",
    "                continue\n",
    "    return result_df\n",
    "\n",
    "def preprocess_dataset(working_dataset, train_test_dataset):\n",
    "    \"\"\"\n",
    "    Preprocesses the dataset by removing duplicate SMILES and rows with errors in MACCS fingerprint calculation.\n",
    "\n",
    "    Args:\n",
    "        working_dataset (pd.DataFrame): The dataset to be preprocessed.\n",
    "        train_test_dataset (pd.DataFrame): The training/testing dataset.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The preprocessed dataset.\n",
    "    \"\"\"\n",
    "    #Filter\n",
    "    logging.info(\"[+] Working dataset: \" + str(len(working_dataset)))\n",
    "    #Check for error smiles while encoding\n",
    "    working_dataset = check_error_fpts(working_dataset, 'pubchem_openeye_iso_smiles')\n",
    "    #Resert index\n",
    "    working_dataset.reset_index(drop=True, inplace=True) \n",
    "    # Get the duplicate SMILES from the training/testing dataset.\n",
    "    duplicate_smiles = working_dataset[working_dataset['pubchem_openeye_iso_smiles'].isin(train_test_dataset['SMILES'])]\n",
    "    logging.info(\"[+] Duplicate with the train-test data: \" + str(len(duplicate_smiles)))\n",
    "    # Get the indices of duplicate smiles in test_working_dataset\n",
    "    duplicate_indices = duplicate_smiles.index\n",
    "    # Remove rows with duplicate SMILES from test_working_dataset\n",
    "    working_dataset.drop(index=duplicate_indices, inplace=True)\n",
    "    #Ending report\n",
    "    logging.info(\"[+] Ending preprocessing: \" + str(len(working_dataset)))\n",
    "    return working_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Screening database preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'DATABASE_URL'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pubchem_dao \u001b[38;5;241m=\u001b[39m \u001b[43mPubchemDAO\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m screening_dao \u001b[38;5;241m=\u001b[39m PubchemScreeningDAO()\n",
      "Cell \u001b[0;32mIn[8], line 18\u001b[0m, in \u001b[0;36mPubchemDAO.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Create connection\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     load_dotenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../env/.env\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection \u001b[38;5;241m=\u001b[39m psycopg2\u001b[38;5;241m.\u001b[39mconnect(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDATABASE_URL\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Get the max_cid and min_cid\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_min_max_cid()\n",
      "File \u001b[0;32m<frozen os>:679\u001b[0m, in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'DATABASE_URL'"
     ]
    }
   ],
   "source": [
    "pubchem_dao = PubchemDAO()\n",
    "screening_dao = PubchemScreeningDAO()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pubchem_dao' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_working_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mpubchem_dao\u001b[49m\u001b[38;5;241m.\u001b[39mget_data_between_cid(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      2\u001b[0m error_dataset \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     test_working_dataset\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m0\u001b[39m]: [\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m13\u001b[39m, \u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m15\u001b[39m],\n\u001b[1;32m      4\u001b[0m     test_working_dataset\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m1\u001b[39m]: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mO=C(NO)c1cnc(NC2(c3ccc(C(F)(F)F)c(F)c3)CC2)nc1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4453\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhellow rodl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCc1cn(C)nc1CN1CCC(c2ccc(C(=O)Nc3ccccc3N)cc2)CC1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqwe\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m####@@qds\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m }\n\u001b[1;32m      6\u001b[0m error_dataset \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(error_dataset)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pubchem_dao' is not defined"
     ]
    }
   ],
   "source": [
    "test_working_dataset = pubchem_dao.get_data_between_cid(1, 10)\n",
    "error_dataset = {\n",
    "    test_working_dataset.columns[0]: [6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "    test_working_dataset.columns[1]: ['O=C(NO)c1cnc(NC2(c3ccc(C(F)(F)F)c(F)c3)CC2)nc1', '', '4453', 'hellow rodl', 'Cc1cn(C)nc1CN1CCC(c2ccc(C(=O)Nc3ccccc3N)cc2)CC1', 'qwe', '####@@qds', None, ' ', '']\n",
    "}\n",
    "error_dataset = pd.DataFrame(error_dataset)\n",
    "test_working_dataset = pd.concat([test_working_dataset, error_dataset], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[09:56:24] SMILES Parse Error: syntax error while parsing: 4453\n",
      "[09:56:24] SMILES Parse Error: Failed parsing SMILES '4453' for input: '4453'\n",
      "[09:56:24] SMILES Parse Error: syntax error while parsing: hellow\n",
      "[09:56:24] SMILES Parse Error: Failed parsing SMILES 'hellow' for input: 'hellow'\n",
      "[09:56:24] SMILES Parse Error: syntax error while parsing: qwe\n",
      "[09:56:24] SMILES Parse Error: Failed parsing SMILES 'qwe' for input: 'qwe'\n",
      "[09:56:24] SMILES Parse Error: syntax error while parsing: ####@@qds\n",
      "[09:56:24] SMILES Parse Error: Failed parsing SMILES '####@@qds' for input: '####@@qds'\n",
      "[09:56:24] SMILES Parse Error: syntax error while parsing: None\n",
      "[09:56:24] SMILES Parse Error: Failed parsing SMILES 'None' for input: 'None'\n"
     ]
    }
   ],
   "source": [
    "test_working_dataset = preprocess_dataset(working_dataset=test_working_dataset, train_test_dataset=train_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "screening_dao.create_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 139999999)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "screening_dao.get_min_max_cid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pubchem_dao' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[+] Starting new process, from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_cid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_cid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m working_dataset \u001b[38;5;241m=\u001b[39m preprocess_dataset(working_dataset\u001b[38;5;241m=\u001b[39m\u001b[43mpubchem_dao\u001b[49m\u001b[38;5;241m.\u001b[39mget_data_between_cid(start_cid, end_cid), train_test_dataset\u001b[38;5;241m=\u001b[39mtrain_test_dataset)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m working_dataset\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m     17\u001b[0m     smiles \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpubchem_openeye_iso_smiles\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pubchem_dao' is not defined"
     ]
    }
   ],
   "source": [
    "# Choosing the starting CID to process by min_cid, and the final cid by max_cid.\n",
    "# Steps: the number of precessed data for each batch\n",
    "min_cid = 0\n",
    "max_cid = 10 ** 6\n",
    "step = 10000\n",
    "cid_range = range(min_cid, max_cid, step)\n",
    "\n",
    "for i in tqdm(cid_range):\n",
    "    start_cid = i\n",
    "    end_cid = i + step - 1\n",
    "    insert_counts = 0\n",
    "    # Starting\n",
    "    logging.info(\"\\n\")\n",
    "    logging.info(f\"[+] Starting new process, from {start_cid} to {end_cid}!\")\n",
    "    working_dataset = preprocess_dataset(working_dataset=pubchem_dao.get_data_between_cid(start_cid, end_cid), train_test_dataset=train_test_dataset)\n",
    "    for idx, row in working_dataset.iterrows():\n",
    "        smiles = row['pubchem_openeye_iso_smiles']\n",
    "        RDLogger.DisableLog('rdApp.info') \n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        molecular_weight = ExactMolWt(mol)\n",
    "        if molecular_weight <= 700:\n",
    "            inserted = screening_dao.insert(cid=row['pubchem_compound_cid'], smiles=smiles, molecular_weight=molecular_weight)\n",
    "            if inserted is True:\n",
    "                insert_counts += 1\n",
    "    # Output insert count\n",
    "    logging.info(\"[+] Insert into database: \" + str(insert_counts))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diversity-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
