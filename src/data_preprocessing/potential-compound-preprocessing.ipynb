{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notification__: The raw data from PubChem database was somewhat have lot of error and duplicate, therefore, we need to clean it first before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "import os\n",
    "import psycopg2\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import logging\n",
    "\n",
    "#MACCS\n",
    "from tqdm import tqdm\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Descriptors import ExactMolWt\n",
    "from rdkit import RDLogger  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='../../output/logs/100mil-hdac2-preprocessing.txt', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PubchemDAO:\n",
    "    \"\"\"\n",
    "    Data access object of the PubChem raw data, the table include two columns: pubchem_compounds_cid, and pubchem_openeye_iso_smiles\n",
    "    \"\"\"\n",
    "    \n",
    "    SELECT_DATA_BETWEEN_CID = \"\"\"SELECT * FROM \n",
    "        compound_screen_10mil WHERE pubchem_compound_cid >= %s and pubchem_compound_cid <= %s;\"\"\"\n",
    "    MAX_CID_QUERY = \"SELECT MAX(pubchem_compound_cid) FROM compound_screen_10mil\"\n",
    "    MIN_CID_QUERY = \"SELECT MIN(pubchem_compound_cid) FROM compound_screen_10mil\"\n",
    "    \n",
    "    max_cid = None\n",
    "    min_cid = None\n",
    "    connection = None\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Create connection\n",
    "        load_dotenv(\"../env/.env\")\n",
    "        self.connection = psycopg2.connect(os.environ['DATABASE_URL'])\n",
    "        # Get the max_cid and min_cid\n",
    "        self.get_min_max_cid()\n",
    "        logging.info(f\"Min CID - Max CID: {self.min_cid} - {self.max_cid}\")\n",
    "    \n",
    "    def get_min_max_cid(self):\n",
    "        with self.connection:\n",
    "            with self.connection.cursor() as cursor:\n",
    "                cursor.execute(self.MIN_CID_QUERY)\n",
    "                self.min_cid = cursor.fetchall()[0][0]\n",
    "                cursor.execute(self.MAX_CID_QUERY)\n",
    "                self.max_cid = cursor.fetchall()[0][0]\n",
    "        \n",
    "    def get_data_between_cid(self, first_cid, second_cid):\n",
    "        if(first_cid < self.min_cid or second_cid > self.max_cid):\n",
    "            logging.info(\"Invalid cid!\")\n",
    "            return\n",
    "        with self.connection:\n",
    "            with self.connection.cursor() as cursor:\n",
    "                cursor.execute(self.SELECT_DATA_BETWEEN_CID, (first_cid, second_cid))\n",
    "                data_list = cursor.fetchall()\n",
    "                column_names = [desc[0] for desc in cursor.description]\n",
    "                return pd.DataFrame(data_list, columns=column_names)\n",
    "\n",
    "class PubchemScreeningDAO:  \n",
    "    \"\"\"\n",
    "    Data access object of the data after preprocessed the PubChem database, \n",
    "        the table include 4 columns: id, cid, smiles, molecular_weight\n",
    "    \"\"\"  \n",
    "    CREATE_PREPROCESSING_TABLE = \"\"\"CREATE TABLE IF NOT EXISTS pubchem_compound_preprocessed (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        cid INTEGER UNIQUE NOT NULL, \n",
    "        smiles TEXT UNIQUE NOT NULL,\n",
    "        molecular_weight decimal NOT NULL\n",
    "    );\n",
    "    CREATE INDEX IF NOT EXISTS idx_cid ON pubchem_compound_preprocessed (cid);\n",
    "    \"\"\"\n",
    "    INSERT_COMPOUND = \"INSERT INTO pubchem_compound_preprocessed (cid, smiles, molecular_weight) VALUES (%s, %s, %s);\"\n",
    "    SELECT_FIRST_DATA = \"SELECT * FROM pubchem_compound_preprocessed LIMIT %s;\"\n",
    "    SELECT_DATA_BY_CID = \"\"\"SELECT * FROM pubchem_compound_preprocessed WHERE cid = %s\"\"\"\n",
    "    SELECT_NUMBERS_OF_ROWS = \"\"\"SELECT COUNT(*) as row_count FROM pubchem_compound_preprocessed;\"\"\"\n",
    "    MAX_CID_QUERY = \"SELECT MAX(cid) FROM pubchem_compound_preprocessed\"\n",
    "    MIN_CID_QUERY = \"SELECT MIN(cid) FROM pubchem_compound_preprocessed\"\n",
    "    \n",
    "    connection = None\n",
    "    \n",
    "    def __init__(self):\n",
    "        load_dotenv(\"../env/.env\")\n",
    "        self.connection = psycopg2.connect(os.environ['DATABASE_URL'])\n",
    "\n",
    "    def create_tables(self):\n",
    "        with self.connection:\n",
    "            with self.connection.cursor() as cursor:\n",
    "                cursor.execute(self.CREATE_PREPROCESSING_TABLE)\n",
    "    \n",
    "    def read_first_rows(self, number_of_data):\n",
    "        with self.connection:\n",
    "            with self.connection.cursor() as cursor:\n",
    "                cursor.execute(self.SELECT_FIRST_1000_ALL_DATA, number_of_data)\n",
    "                column_names = [desc[0] for desc in cursor.description]\n",
    "                data_list = cursor.fetchall()\n",
    "                return pd.DataFrame(data_list, columns=column_names)\n",
    "    \n",
    "    def insert(self, cid, smiles, molecular_weight):\n",
    "        with self.connection:\n",
    "            with self.connection.cursor() as cursor:\n",
    "                try:\n",
    "                    cursor.execute(self.INSERT_COMPOUND, (cid, smiles, molecular_weight))\n",
    "                    return True\n",
    "                except psycopg2.IntegrityError as error:\n",
    "                    if 'duplicate key value violates unique constraint' in str(error):\n",
    "                        logging.error(f\"Skipping data with cid={cid} due to unique constraint violation.\")\n",
    "                    else:\n",
    "                        logging.error(str(error))\n",
    "                        raise  # Re-raise the exception if it's not related to unique constraint violation\n",
    "                except Exception as e:\n",
    "                    logging.error(\"An exception occurred: \" + str(e))\n",
    "        return False  # Return False if no successful insertion or if an exception occurs\n",
    "    \n",
    "    def get_number_of_rows(self):\n",
    "        with self.connection:\n",
    "            with self.connection.cursor() as cursor:\n",
    "                cursor.execute(self.SELECT_NUMBERS_OF_ROWS)\n",
    "                nor = cursor.fetchall()\n",
    "                return nor\n",
    "            \n",
    "    def get_min_max_cid(self):\n",
    "        with self.connection:\n",
    "            with self.connection.cursor() as cursor:\n",
    "                cursor.execute(self.MIN_CID_QUERY)\n",
    "                min_cid = cursor.fetchall()[0][0]\n",
    "                cursor.execute(self.MAX_CID_QUERY)\n",
    "                max_cid = cursor.fetchall()[0][0]\n",
    "                return min_cid, max_cid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the train - test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_path = \"../../data_for_modeling/train_test_data/HDAC2_train_test_data_final.xlsx\"\n",
    "train_dataset = pd.read_excel(train_test_path, sheet_name='train_dataset')\n",
    "test_dataset = pd.read_excel(train_test_path, sheet_name='test_dataset')\n",
    "validation_dataset = pd.read_excel(train_test_path, sheet_name='validation_dataset')\n",
    "\n",
    "train_test_dataset = pd.concat([train_dataset, test_dataset, validation_dataset], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016 504 281 2801\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset), len(test_dataset), len(validation_dataset), len(train_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CID</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>AVG_IC50_nM</th>\n",
       "      <th>FINAL_LABEL</th>\n",
       "      <th>ZBG Classified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44138033</td>\n",
       "      <td>COC(=O)c1ccc(CO/N=C/c2ccc(/C=C/C(=O)NO)cc2)cc1</td>\n",
       "      <td>15800.0</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>164616411</td>\n",
       "      <td>CC[C@H](NC(=O)C1CN(C)C1)c1ncc(-c2cc3ccccc3nc2O...</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>135357843</td>\n",
       "      <td>O=C(NO)c1ccc(Cn2nnnc2-c2cccs2)cc1</td>\n",
       "      <td>3698.0</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>142506189</td>\n",
       "      <td>CC[C@H](Nc1ncnc2[nH]cnc12)c1nc2cccc(NCc3ccc(C(...</td>\n",
       "      <td>7173.0</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155537112</td>\n",
       "      <td>CN(C)c1ccc(C(=O)N(CC(=O)NCc2ccccc2)Cc2ccc(C(=O...</td>\n",
       "      <td>283.0</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CID                                             SMILES  AVG_IC50_nM  \\\n",
       "0   44138033     COC(=O)c1ccc(CO/N=C/c2ccc(/C=C/C(=O)NO)cc2)cc1      15800.0   \n",
       "1  164616411  CC[C@H](NC(=O)C1CN(C)C1)c1ncc(-c2cc3ccccc3nc2O...      50000.0   \n",
       "2  135357843                  O=C(NO)c1ccc(Cn2nnnc2-c2cccs2)cc1       3698.0   \n",
       "3  142506189  CC[C@H](Nc1ncnc2[nH]cnc12)c1nc2cccc(NCc3ccc(C(...       7173.0   \n",
       "4  155537112  CN(C)c1ccc(C(=O)N(CC(=O)NCc2ccccc2)Cc2ccc(C(=O...        283.0   \n",
       "\n",
       "  FINAL_LABEL  ZBG Classified  \n",
       "0    Inactive               1  \n",
       "1    Inactive              15  \n",
       "2    Inactive               1  \n",
       "3    Inactive               1  \n",
       "4    Inactive               4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking and insert data into the preprocessing table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_error_fpts(check_dataset, smiles_column):\n",
    "    \"\"\"\n",
    "    Checks for errors in MACCS fingerprint calculation.\n",
    "\n",
    "    Args:\n",
    "        check_dataset (pd.DataFrame): The dataset to be checked.\n",
    "        smiles_column (str): The name of the SMILES column.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The rows with errors in MACCS fingerprint calculation.\n",
    "    \"\"\"\n",
    "    result_df = pd.DataFrame(columns=check_dataset.columns)\n",
    "    for index, row in check_dataset.iterrows():\n",
    "        current_smiles = str(row[smiles_column]).strip()\n",
    "        if current_smiles is not None and len(current_smiles) > 0:\n",
    "            try:\n",
    "                RDLogger.DisableLog('rdApp.info')\n",
    "                mol = Chem.MolFromSmiles(current_smiles)\n",
    "                if mol is not None:\n",
    "                    result_df = pd.concat([result_df, row.to_frame().T], axis=0)  # Concatenate the current row                \n",
    "                else:\n",
    "                    logging.info(\"Could not interpret \" + current_smiles + \" to mol object!\")\n",
    "            except Exception as e:\n",
    "                logging.error(\"An exception occurred at row \" + str(index) + \": \" + str(e))\n",
    "                continue\n",
    "    return result_df\n",
    "\n",
    "def preprocess_dataset(working_dataset, train_test_dataset):\n",
    "    \"\"\"\n",
    "    Preprocesses the dataset by removing duplicate SMILES and rows with errors in MACCS fingerprint calculation.\n",
    "\n",
    "    Args:\n",
    "        working_dataset (pd.DataFrame): The dataset to be preprocessed.\n",
    "        train_test_dataset (pd.DataFrame): The training/testing dataset.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The preprocessed dataset.\n",
    "    \"\"\"\n",
    "    #Filter\n",
    "    logging.info(\"[+] Working dataset: \" + str(len(working_dataset)))\n",
    "    #Check for error smiles while encoding\n",
    "    working_dataset = check_error_fpts(working_dataset, 'pubchem_openeye_iso_smiles')\n",
    "    #Resert index\n",
    "    working_dataset.reset_index(drop=True, inplace=True) \n",
    "    # Get the duplicate SMILES from the training/testing dataset.\n",
    "    duplicate_smiles = working_dataset[working_dataset['pubchem_openeye_iso_smiles'].isin(train_test_dataset['SMILES'])]\n",
    "    logging.info(\"[+] Duplicate with the train-test data: \" + str(len(duplicate_smiles)))\n",
    "    # Get the indices of duplicate smiles in test_working_dataset\n",
    "    duplicate_indices = duplicate_smiles.index\n",
    "    # Remove rows with duplicate SMILES from test_working_dataset\n",
    "    working_dataset.drop(index=duplicate_indices, inplace=True)\n",
    "    #Ending report\n",
    "    logging.info(\"[+] Ending preprocessing: \" + str(len(working_dataset)))\n",
    "    return working_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Screening database preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubchem_dao = PubchemDAO()\n",
    "screening_dao = PubchemScreeningDAO()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_working_dataset = pubchem_dao.get_data_between_cid(1, 10)\n",
    "error_dataset = {\n",
    "    test_working_dataset.columns[0]: [6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "    test_working_dataset.columns[1]: ['O=C(NO)c1cnc(NC2(c3ccc(C(F)(F)F)c(F)c3)CC2)nc1', '', '4453', 'hellow rodl', 'Cc1cn(C)nc1CN1CCC(c2ccc(C(=O)Nc3ccccc3N)cc2)CC1', 'qwe', '####@@qds', None, ' ', '']\n",
    "}\n",
    "error_dataset = pd.DataFrame(error_dataset)\n",
    "test_working_dataset = pd.concat([test_working_dataset, error_dataset], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[09:56:24] SMILES Parse Error: syntax error while parsing: 4453\n",
      "[09:56:24] SMILES Parse Error: Failed parsing SMILES '4453' for input: '4453'\n",
      "[09:56:24] SMILES Parse Error: syntax error while parsing: hellow\n",
      "[09:56:24] SMILES Parse Error: Failed parsing SMILES 'hellow' for input: 'hellow'\n",
      "[09:56:24] SMILES Parse Error: syntax error while parsing: qwe\n",
      "[09:56:24] SMILES Parse Error: Failed parsing SMILES 'qwe' for input: 'qwe'\n",
      "[09:56:24] SMILES Parse Error: syntax error while parsing: ####@@qds\n",
      "[09:56:24] SMILES Parse Error: Failed parsing SMILES '####@@qds' for input: '####@@qds'\n",
      "[09:56:24] SMILES Parse Error: syntax error while parsing: None\n",
      "[09:56:24] SMILES Parse Error: Failed parsing SMILES 'None' for input: 'None'\n"
     ]
    }
   ],
   "source": [
    "test_working_dataset = preprocess_dataset(working_dataset=test_working_dataset, train_test_dataset=train_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "screening_dao.create_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 139999999)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "screening_dao.get_min_max_cid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 62.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# Choosing the starting CID to process by min_cid, and the final cid by max_cid.\n",
    "# Steps: the number of precessed data for each batch\n",
    "min_cid = 0\n",
    "max_cid = 10 ** 6\n",
    "step = 10000\n",
    "cid_range = range(min_cid, max_cid, step)\n",
    "\n",
    "for i in tqdm(cid_range):\n",
    "    start_cid = i\n",
    "    end_cid = i + step - 1\n",
    "    insert_counts = 0\n",
    "    # Starting\n",
    "    logging.info(\"\\n\")\n",
    "    logging.info(f\"[+] Starting new process, from {start_cid} to {end_cid}!\")\n",
    "    working_dataset = preprocess_dataset(working_dataset=pubchem_dao.get_data_between_cid(start_cid, end_cid), train_test_dataset=train_test_dataset)\n",
    "    for idx, row in working_dataset.iterrows():\n",
    "        smiles = row['pubchem_openeye_iso_smiles']\n",
    "        RDLogger.DisableLog('rdApp.info') \n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        molecular_weight = ExactMolWt(mol)\n",
    "        if molecular_weight <= 700:\n",
    "            inserted = screening_dao.insert(cid=row['pubchem_compound_cid'], smiles=smiles, molecular_weight=molecular_weight)\n",
    "            if inserted is True:\n",
    "                insert_counts += 1\n",
    "    # Output insert count\n",
    "    logging.info(\"[+] Insert into database: \" + str(insert_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(87263665,)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_rows = screening_dao.get_number_of_rows()\n",
    "number_of_rows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diversity-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
